# gemini-mm-embeddings

This notebook outlines how to interact with Vertex AI's Gemini Vision Pro GenAI model to inspect images and generate detailed information about its content. Visual Question Answering (VQA) lets you provide an image to the model and ask a question about the image's contents. In response to your question you get one or more natural language answers. In this example we will identify products in an image, output the description and item details in a CSV format and then create embeddings using the Gemini embeddings API.
